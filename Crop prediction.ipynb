{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SWAROOPBHAGWAT/Crop-Prediction/blob/main/Crop%20prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3uplTySRRvCf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import metrics\n",
        "from sklearn import tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUMkP0tTkcmN",
        "outputId": "47d625f2-6808-4ce1-d452-6b0e181e786b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "woQOgQm1XbNW",
        "outputId": "70ae6239-38fa-4f5d-e304-7017d76ec14c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/dataset/Crop_recommendation.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-24a4f8e1ea4d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/dataset/Crop_recommendation.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/dataset/Crop_recommendation.csv'"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/dataset/Crop_recommendation.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HIge4sRaREI"
      },
      "source": [
        "### ***Data Analysis : EDA***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPhXNQW9Xewo"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5Mifk5WXhPt"
      },
      "outputs": [],
      "source": [
        "df.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sh8q3knjXj5J"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MGPIDhlXlsR"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0rrwHC5Xn9y"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Irg-0HBMXqPK"
      },
      "outputs": [],
      "source": [
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFzME3KTXscF"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsCfDSeGXvVe"
      },
      "outputs": [],
      "source": [
        "df['label'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DU8zAsh4Xx-U"
      },
      "outputs": [],
      "source": [
        "df['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dA9HtGiuYVyO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wqwdMB9YKg_"
      },
      "source": [
        "### **Graphs to Analyse the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHR9YgMZX7GZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "numeric_features = [feature for feature in df.columns if df[feature].dtype != 'O']\n",
        "\n",
        "plt.figure(figsize=(20, 220))  # Increase the figure size\n",
        "\n",
        "for i, col in enumerate(numeric_features):\n",
        "    plt.subplot(60, 3, i+1)\n",
        "    sns.distplot(x=df[col], color='indianred')\n",
        "    plt.xlabel(col, weight='bold', fontsize=14)\n",
        "    plt.ylabel('Density', weight='bold', fontsize=14)  # Increase the font size\n",
        "    plt.xticks(fontsize=12)  # Increase the font size of tick labels on x-axis\n",
        "    plt.yticks(fontsize=12)  # Increase the font size of tick labels on y-axis\n",
        "    plt.title(f'Distribution of {col}', weight='bold', fontsize=16)  # Increase the font size\n",
        "    plt.tight_layout()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hkiyLZlZ9ZV"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(25, 4))\n",
        "sns.countplot(x=df[\"label\"])\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8v2yUcU_bqlk"
      },
      "source": [
        "### **KDE Plot** || **Violin Plot** || **Box Plot**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwytY_OCaG20"
      },
      "outputs": [],
      "source": [
        "plt.style.use('ggplot')\n",
        "sns.set_palette(\"hls\", 8)\n",
        "for i in df.columns[:-1]:\n",
        "    fig,ax=plt.subplots(1,3,figsize=(18,4))\n",
        "    sns.histplot(data=df,x=i,kde=True,bins=40,ax=ax[0])\n",
        "    sns.violinplot(data=df,x=i,ax=ax[1])\n",
        "    sns.boxplot(data=df,x=i,ax=ax[2])\n",
        "    plt.suptitle(f'Visualizing {i}',size=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxfIImvNdi0i"
      },
      "source": [
        "### **Heatmap**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwnlSQ4WaVLT"
      },
      "outputs": [],
      "source": [
        "# Exclude non-numeric columns\n",
        "numeric_columns = df.select_dtypes(include=['number'])\n",
        "\n",
        "# Calculate correlation matrix\n",
        "correlation_matrix = numeric_columns.corr()\n",
        "\n",
        "# Plot the heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title('Correlation Matrix Heatmap')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKylRNUUdsdJ"
      },
      "source": [
        "### **Pairplot**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LiWmX2GcUSq"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(data=df,hue='label')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHuHBnW7d1rb"
      },
      "source": [
        "## **Seperating features and target label**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oymLjnbNx0Q7"
      },
      "outputs": [],
      "source": [
        "features = df[['N', 'P','K','temperature', 'humidity', 'ph', 'rainfall']]\n",
        "target = df['label']\n",
        "labels = df['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2AlWLzqbzyaZ"
      },
      "outputs": [],
      "source": [
        "# Initializing empty lists to append all model's name and corresponding name\n",
        "acc = []\n",
        "model = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ky-q_i0Zd_PN"
      },
      "source": [
        "## **Splitting the data into training and testing sets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSZuC2BVz06X"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "Xtrain, Xtest, Ytrain, Ytest = train_test_split(features,target,test_size = 0.2,random_state =2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSkt6i9eeDqU"
      },
      "source": [
        "## **Decision Tree**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARud7-mjz4iH"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "DecisionTree = DecisionTreeClassifier(criterion=\"entropy\",random_state=2,max_depth=5)\n",
        "\n",
        "DecisionTree.fit(Xtrain,Ytrain)\n",
        "\n",
        "predicted_values = DecisionTree.predict(Xtest)\n",
        "x = metrics.accuracy_score(Ytest, predicted_values)\n",
        "acc.append(x)\n",
        "model.append('Decision Tree')\n",
        "print(\"DecisionTrees's Accuracy is: \", x*100)\n",
        "\n",
        "print(classification_report(Ytest,predicted_values))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-m_XJnz0HHn"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(Ytest, predicted_values)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, cmap=\"OrRd\", fmt=\"d\", xticklabels=np.unique(Ytest), yticklabels=np.unique(Ytest))\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uz6cOKHz10u3"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Cross validation score (Decision Tree)\n",
        "score = cross_val_score(DecisionTree, features, target,cv=5)\n",
        "score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbuF6jKBePtk"
      },
      "source": [
        "## **Guassian Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7Wg1qg17Jvb"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Assuming Xtrain, Ytrain, Xtest, Ytest are your training and test data\n",
        "\n",
        "# Initialize and train Naive Bayes classifier\n",
        "NaiveBayes = GaussianNB()\n",
        "NaiveBayes.fit(Xtrain, Ytrain)\n",
        "\n",
        "# Make predictions\n",
        "predicted_values = NaiveBayes.predict(Xtest)\n",
        "\n",
        "# Calculate accuracy and append to acc list\n",
        "x = accuracy_score(Ytest, predicted_values)\n",
        "acc.append(x)\n",
        "\n",
        "# Append model name to the model list\n",
        "model.append('Naive Bayes')\n",
        "\n",
        "# Print accuracy and classification report\n",
        "print(\"Naive Bayes's Accuracy is:\", x)\n",
        "print(classification_report(Ytest, predicted_values))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJn8c3TG8GBn"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm = confusion_matrix(Ytest, predicted_values)\n",
        "\n",
        "# Plot confusion matrix for Naive Bayes\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, cmap=\"OrRd\", fmt=\"d\", xticklabels=np.unique(Ytest), yticklabels=np.unique(Ytest))\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('Confusion Matrix - Naive Bayes')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1IWK9hxm84St"
      },
      "outputs": [],
      "source": [
        "score = cross_val_score(NaiveBayes,features,target,cv=5)\n",
        "score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNoox56BeTal"
      },
      "source": [
        "## **Support Vector Machine (SVM)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSmzfilH9BsW"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "SVM = SVC()\n",
        "\n",
        "SVM.fit(Xtrain,Ytrain)\n",
        "\n",
        "predicted_values = SVM.predict(Xtest)\n",
        "\n",
        "x = metrics.accuracy_score(Ytest, predicted_values)\n",
        "acc.append(x)\n",
        "model.append('SVM')\n",
        "print(\"SVM's Accuracy is: \", x)\n",
        "\n",
        "print(classification_report(Ytest,predicted_values))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zRQ1-b29mvE"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(Ytest, predicted_values)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, cmap=\"OrRd\", fmt=\"d\", xticklabels=np.unique(Ytest), yticklabels=np.unique(Ytest))\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJ8u4wn89wSM"
      },
      "outputs": [],
      "source": [
        "# Cross validation score (SVM)\n",
        "score = cross_val_score(SVM,features,target,cv=5)\n",
        "score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ru3Zhw2eYFI"
      },
      "source": [
        "## **Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTneXX0G9y1G"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "LogReg = LogisticRegression(random_state=2)\n",
        "\n",
        "LogReg.fit(Xtrain,Ytrain)\n",
        "\n",
        "predicted_values = LogReg.predict(Xtest)\n",
        "\n",
        "x = metrics.accuracy_score(Ytest, predicted_values)\n",
        "acc.append(x)\n",
        "model.append('Logistic Regression')\n",
        "print(\"Logistic Regression's Accuracy is: \", x)\n",
        "\n",
        "print(classification_report(Ytest,predicted_values))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJOQXkCD93xG"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(Ytest, predicted_values)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, cmap=\"OrRd\", fmt=\"d\", xticklabels=np.unique(Ytest), yticklabels=np.unique(Ytest))\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_MNijlp96dZ"
      },
      "outputs": [],
      "source": [
        "# Cross validation score (Logistic Regression)\n",
        "score = cross_val_score(LogReg,features,target,cv=5)\n",
        "score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDBoBJT0ec76"
      },
      "source": [
        "## **Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ku16Bt09-BPp"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "RF = RandomForestClassifier(n_estimators=20, random_state=0)\n",
        "RF.fit(Xtrain,Ytrain)\n",
        "\n",
        "predicted_values = RF.predict(Xtest)\n",
        "\n",
        "x = metrics.accuracy_score(Ytest, predicted_values)\n",
        "acc.append(x)\n",
        "model.append('RF')\n",
        "print(\"RF's Accuracy is: \", x)\n",
        "\n",
        "print(classification_report(Ytest,predicted_values))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H783jssX-IFS"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(Ytest, predicted_values)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, cmap=\"OrRd\", fmt=\"d\", xticklabels=np.unique(Ytest), yticklabels=np.unique(Ytest))\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJwchB4n-Ilg"
      },
      "outputs": [],
      "source": [
        "# Cross validation score (Random Forest)\n",
        "score = cross_val_score(RF,features,target,cv=5)\n",
        "score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MILrYsVOepLq"
      },
      "source": [
        "## **Accuracy of each model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zh1asz_b-agt"
      },
      "outputs": [],
      "source": [
        "accuracy_models = dict(zip(model, acc))\n",
        "for k, v in accuracy_models.items():\n",
        "    print (k, '-->', v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgcwj9ts-_67"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming accuracy_models is a dictionary containing model names as keys and corresponding accuracies as values\n",
        "\n",
        "# Plotting the bar graph\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.bar(accuracy_models.keys(), accuracy_models.values(), color='skyblue')\n",
        "\n",
        "# Adding percentage annotations on top of the bars\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width() / 2, yval + 0.01, f'{yval*100:.2f}%', ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy of Different Models')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "\n",
        "# Displaying the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njGios6be68g"
      },
      "source": [
        "# **Hyperparameter Tuning for Random Forest Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ulFo1JGHM7k"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Define the parameter grid for Randomized Search\n",
        "param_grid = {\n",
        "    'n_estimators': np.arange(50, 200),\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': np.arange(2, 25),\n",
        "    'min_samples_split': np.arange(2, 25),\n",
        "    'min_samples_leaf': np.arange(2, 25)\n",
        "}\n",
        "\n",
        "# Initialize Random Forest Classifier\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "# Initialize RandomizedSearchCV with the Random Forest classifier and parameter grid\n",
        "rscv_model = RandomizedSearchCV(rf, param_distributions=param_grid, n_iter=100, cv=5, random_state=42)\n",
        "\n",
        "# Fit RandomizedSearchCV to the training data\n",
        "rscv_model.fit(Xtrain, Ytrain)\n",
        "\n",
        "# Get the best estimator (best model) from RandomizedSearchCV\n",
        "best_estimator = rscv_model.best_estimator_\n",
        "\n",
        "# Print the best parameters found by RandomizedSearchCV\n",
        "print(\"Best Parameters:\", rscv_model.best_params_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KQ3HGsjK_EP"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "best_rf_model = RandomForestClassifier(n_estimators=192, min_samples_split=17, min_samples_leaf=2, max_depth=18, criterion='entropy', random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrQNC9ayLDRE"
      },
      "outputs": [],
      "source": [
        "best_rf_model.fit(Xtrain, Ytrain)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QaZsj7sfQ0l"
      },
      "source": [
        "# **Training with the best parameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byGYATpWLQwT"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Define the best hyperparameters\n",
        "best_params = {\n",
        "    'n_estimators': 192,\n",
        "    'min_samples_split': 17,\n",
        "    'min_samples_leaf': 2,\n",
        "    'max_depth': 18,\n",
        "    'criterion': 'entropy'\n",
        "}\n",
        "\n",
        "# Initialize the Random Forest classifier with the best hyperparameters\n",
        "best_RF = RandomForestClassifier(**best_params, random_state=0)\n",
        "\n",
        "# Train the Random Forest classifier using the best hyperparameters\n",
        "best_RF.fit(Xtrain, Ytrain)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predicted_values = best_RF.predict(Xtest)\n",
        "\n",
        "# Calculate accuracy and append to the accuracy list\n",
        "x = metrics.accuracy_score(Ytest, predicted_values)\n",
        "acc.append(x)\n",
        "model.append('RF')\n",
        "print(\"RF's Accuracy is: \", x)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reuDe44Ofszu"
      },
      "source": [
        "# **Succesfull Prediction using sample data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnHvrlt8Trmt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Sample input data\n",
        "N = 200\n",
        "P = 50.6\n",
        "K = 0.29\n",
        "temperature = 10.603016\n",
        "humidity = 20.3\n",
        "ph = 5\n",
        "rainfall = 110.91\n",
        "\n",
        "# Create a dictionary with feature names and values\n",
        "input_data = {\n",
        "    'N': N,\n",
        "    'P': P,\n",
        "    'K': K,\n",
        "    'temperature': temperature,\n",
        "    'humidity': humidity,\n",
        "    'ph': ph,\n",
        "    'rainfall': rainfall\n",
        "}\n",
        "\n",
        "# Convert the dictionary to a DataFrame\n",
        "df = pd.DataFrame([input_data])\n",
        "\n",
        "# Extract feature names\n",
        "feature_names = df.columns.tolist()\n",
        "\n",
        "# Convert DataFrame to numpy array for prediction\n",
        "data = df.values\n",
        "\n",
        "# Make prediction using the trained RandomForestClassifier\n",
        "prediction = RF.predict(data)\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qj7h0HrqUpiO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Sample input data\n",
        "N = 50\n",
        "P = 100\n",
        "K = 150\n",
        "temperature = 25.603016\n",
        "humidity = 60.3\n",
        "ph = 5\n",
        "rainfall = 110.91\n",
        "\n",
        "# Create a dictionary with feature names and values\n",
        "input_data = {\n",
        "    'N': N,\n",
        "    'P': P,\n",
        "    'K': K,\n",
        "    'temperature': temperature,\n",
        "    'humidity': humidity,\n",
        "    'ph': ph,\n",
        "    'rainfall': rainfall\n",
        "}\n",
        "\n",
        "# Convert the dictionary to a DataFrame\n",
        "df = pd.DataFrame([input_data])\n",
        "\n",
        "# Extract feature names\n",
        "feature_names = df.columns.tolist()\n",
        "\n",
        "# Convert DataFrame to numpy array for prediction\n",
        "data = df.values\n",
        "\n",
        "# Make prediction using the trained RandomForestClassifier\n",
        "prediction = RF.predict(data)\n",
        "print(prediction)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzZg--rBTYcx"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "pickle_file_path = '/content/drive/My Drive/crop_prediction_model.pkl'\n",
        "\n",
        "# Open the file in binary write mode ('wb') and dump the RF model into it\n",
        "with open(pickle_file_path, 'wb') as f:\n",
        "    pickle.dump(RF, f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2CjkA0hRfJI"
      },
      "outputs": [],
      "source": [
        "!pip install flask-ngrok\n",
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjkQ34mtaXqc"
      },
      "source": [
        "# **Change Directory**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkUvBP2GaaMr"
      },
      "outputs": [],
      "source": [
        "cd/content/drive/MyDrive/Colab Notebooks/data/Flask-deploy-model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8xbJaooYfQj"
      },
      "source": [
        "# **Import Required Packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BISdge9iSjM_"
      },
      "outputs": [],
      "source": [
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask, request, render_template_string\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3isXhjnYnHr"
      },
      "source": [
        "# **Create Flask App**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--CamIWmvkPe"
      },
      "outputs": [],
      "source": [
        "!ngrok authtoken 2fbc4yti3QB2SA8H3cHWfh1LwXm_6cvcq1QpaKfN4VfGVNtUQ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qYG9haesFtS"
      },
      "outputs": [],
      "source": [
        "from flask import Flask, render_template, request\n",
        "import pickle\n",
        "import numpy as np\n",
        "import requests\n",
        "from pyngrok import ngrok  # Import ngrok module\n",
        "from flask import jsonify\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Load the trained model from the pickle file\n",
        "with open('crop_prediction_model.pkl', 'rb') as f:\n",
        "    model = pickle.load(f)\n",
        "\n",
        "\n",
        "def predict_crop(N, P, K, temperature, humidity, ph, rainfall):\n",
        "    # Make prediction\n",
        "    prediction = model.predict([[N, P, K, temperature, humidity, ph, rainfall]])\n",
        "    return prediction[0]\n",
        "\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return render_template('index.html')\n",
        "\n",
        "@app.route('/favicon.ico')\n",
        "def favicon():\n",
        "    return '', 204\n",
        "\n",
        "@app.route('/getprediction', methods=['POST'])\n",
        "def getprediction():\n",
        "    # Get input values from the form\n",
        "    try:\n",
        "        # Get input values from the form\n",
        "        N = float(request.form.get('N', 0.0))  # Provide a default value of 0.0 if 'N' is missing or invalid\n",
        "        P = float(request.form.get('P', 0.0))\n",
        "        K = float(request.form.get('K', 0.0))\n",
        "        temperature = float(request.form.get('temperature', 0.0))\n",
        "        humidity = float(request.form.get('humidity', 0.0))\n",
        "        ph = float(request.form.get('ph', 0.0))\n",
        "        rainfall = float(request.form.get('rainfall', 0.0))\n",
        "\n",
        "        # Make prediction\n",
        "        prediction = predict_crop(N, P, K, temperature, humidity, ph, rainfall)\n",
        "\n",
        "        # Return prediction result as JSON\n",
        "        return jsonify({'output': 'Predicted Crop: {}'.format(prediction)})\n",
        "\n",
        "        if image_data:\n",
        "            return jsonify({'output': 'Predicted Crop: {}'.format(prediction), 'image': image_data})\n",
        "        else:\n",
        "            return jsonify({'output': 'Predicted Crop: {}'.format(prediction), 'error': 'Image not found for predicted crop'})\n",
        "\n",
        "    except ValueError:\n",
        "        return jsonify({'error': 'Invalid input data format'})\n",
        "    except Exception as e:\n",
        "        return jsonify({'error': 'Failed to make prediction'})\n",
        "\n",
        "    # Return the prediction\n",
        "    return render_template('index.html', output='Predicted Crop: {}'.format(prediction))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Connect ngrok tunnel\n",
        "    ngrok_tunnel = ngrok.connect(5000)\n",
        "    print('Public URL:', ngrok_tunnel.public_url)\n",
        "\n",
        "\n",
        "# Keep the Flask app running\n",
        "app.run()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}